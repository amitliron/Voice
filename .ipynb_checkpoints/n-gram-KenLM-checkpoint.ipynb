{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adadd72d",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Links </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2039e",
   "metadata": {},
   "source": [
    "HF With KenLM:\n",
    "https://huggingface.co/blog/wav2vec2-with-ngram\n",
    "\n",
    "Hebrew Dataset:\n",
    "https://huggingface.co/datasets/HeNLP/HeDC4/blob/main/HeDC4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ff773",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Imports </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0845780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets        import load_dataset\n",
    "\n",
    "from transformers    import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from transformers    import Wav2Vec2ProcessorWithLM\n",
    "from transformers    import AutoProcessor\n",
    "\n",
    "from huggingface_hub import Repository\n",
    "from huggingface_hub import notebook_login\n",
    "from pyctcdecode     import build_ctcdecoder\n",
    "\n",
    "import torch\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895acb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d35ece2b",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> 1. Decoding audio data with Wav2Vec2 and a language model </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1aba3",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#33DAC8;\"> <left> NO LM: </left></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1edfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_demo (/home/amitli/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_demo/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id'],\n",
       "    num_rows: 73\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "694ad1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he tells us that at this festive season of the year with christmas and roast beef looming before us similes drawn from eating and its results occur most readily to the mind'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_sample = dataset[2]\n",
    "audio_sample[\"text\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80f21eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-100h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.mask_time_emb_vector']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-100h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-100h\")\n",
    "model     = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-100h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11413988",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(audio_sample[\"audio\"][\"array\"],\n",
    "                   sampling_rate  = audio_sample[\"audio\"][\"sampling_rate\"],\n",
    "                   return_tensors =\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d33fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f8d5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he tells us that at this festive season of the year with christmaus and rose beef looming before us simalyis drawn from eating and its results occur most readily to the mind'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "transcription[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f5e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a996cf",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#33DAC8;\"> <left> With LM: </left></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fc6009f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18684b36ea5444a59203d1479faaa2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = Wav2Vec2ProcessorWithLM.from_pretrained(\"patrickvonplaten/wav2vec2-base-100h-with-lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d6be54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 624, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dfe87a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"' </s> <pad> <s> <unk> A B C D E F G H I J K L M N O P Q R S T U V W X Y Z |\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(sorted(processor.tokenizer.get_vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a56e8c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he tells us that at this festive season of the year with christmas and rose beef looming before us similes drawn from eating and its results occur most readily to the mind'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription = processor.batch_decode(logits.numpy()).text\n",
    "transcription[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee0eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c743c0da",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> 2. Getting data for your language model </center></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4207574d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff43bce1f534191bada9fad03bd5cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e5116c7ed94937aaa2a7e1f648caf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/457k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a636a9a4b094cba8f9058884352bb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/59.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset europarl_bilingual/en-sv to /home/amitli/.cache/huggingface/datasets/europarl_bilingual/en-sv-lang1=en,lang2=sv/8.0.0/2ab0200e7729616bfd4a4df6bfb29b31746ceb5a59f8c75c02ca35e1ebead950...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6eb2c1e22034d4ca1a8fd092a6aee63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/142M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8533ca89e4145509c132feeb8f18c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/127M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e800bda9738487ca1b20f380febf7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1892723 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset europarl_bilingual downloaded and prepared to /home/amitli/.cache/huggingface/datasets/europarl_bilingual/en-sv-lang1=en,lang2=sv/8.0.0/2ab0200e7729616bfd4a4df6bfb29b31746ceb5a59f8c75c02ca35e1ebead950. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "target_lang = \"sv\"\n",
    "dataset     = load_dataset(\"europarl_bilingual\", lang1=\"en\", lang2=target_lang, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "447638a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " # change to the ignored characters of your fine-tuned model\n",
    "chars_to_ignore_regex = '[,?.!\\-\\;\\:\"“%‘”�—’…–]' \n",
    "\n",
    "def extract_text(batch):\n",
    "    text          = batch[\"translation\"][target_lang]\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, \"\", text.lower())\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c002fa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['translation']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5247c293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1892723 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(extract_text, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25a9cd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1892723\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef421cc",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#33DAC8;\"> <left> Push Dataset to HuggingFace: </left></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a50176d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved to /home/amitli/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72cdafc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2ccfe257cf4f278d0829df9cdf8432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaab54d432a448dd9a9542794415af8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1893 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2867dd5c2e4e37b3705f6c2c7832c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(f\"{target_lang}_corpora_parliament_processed\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc569b4b",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> 3. Build an n-gram with KenLM </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8249feda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e36016281eb408fa44fd2420d7546d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/382 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/amitli/.cache/huggingface/datasets/laro1___parquet/laro1--sv_corpora_parliament_processed-09c2e735160f274d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f427fb34104d73ac14bf492db1c018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5da0e56b24454ca558f1cb8dec5609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/162M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d713024ece2f475d95850119d2e30187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1892723 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/amitli/.cache/huggingface/datasets/laro1___parquet/laro1--sv_corpora_parliament_processed-09c2e735160f274d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "username    = \"laro1\" \n",
    "target_lang = \"sv\"\n",
    "dataset     = load_dataset(f\"{username}/{target_lang}_corpora_parliament_processed\", split=\"train\")\n",
    "\n",
    "with open(\"text.txt\", \"w\") as file:\n",
    "    file.write(\" \".join(dataset[\"text\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ecb7ad",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#33DAC8;\"> <left> kenlm/build/bin/lmplz -o 5 <\"text.txt\" > \"5gram.arpa\" </left></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"5gram.arpa\", \"r\") as read_file, open(\"5gram_correct.arpa\", \"w\") as write_file:\n",
    "    \n",
    "    has_added_eos = False\n",
    "    \n",
    "    for line in read_file:        \n",
    "        \n",
    "        if not has_added_eos and \"ngram 1=\" in line:\n",
    "            count = line.strip().split(\"=\")[-1]\n",
    "            write_file.write(line.replace(f\"{count}\", f\"{int(count)+1}\"))\n",
    "            \n",
    "        elif not has_added_eos and \"<s>\" in line:\n",
    "            \n",
    "            write_file.write(line)\n",
    "            write_file.write(line.replace(\"<s>\", \"</s>\"))\n",
    "            has_added_eos = True\n",
    "        else:\n",
    "            write_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f386e9",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> 4. Combine an n-gram with Wav2Vec2 </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"hf-test/xls-r-300m-sv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict        = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), \n",
    "                                                     key = lambda item: item[1])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee73bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = build_ctcdecoder(\n",
    "    labels           = list(sorted_vocab_dict.keys()),\n",
    "    kenlm_model_path = \"5gram_correct.arpa\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43609926",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor = processor.feature_extractor,\n",
    "    tokenizer         = processor.tokenizer,\n",
    "    decoder           = decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Repository(local_dir  = \"xls-r-300m-sv\", \n",
    "                  clone_from = \"hf-test/xls-r-300m-sv\")\n",
    "\n",
    "processor_with_lm.save_pretrained(\"xls-r-300m-sv\")\n",
    "\n",
    "repo.push_to_hub(commit_message=\"Upload lm-boosted decoder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
