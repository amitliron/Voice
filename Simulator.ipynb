{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd57df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bb9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6e87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c86e75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from pyannote.audio                    import Model\n",
    "from pyannote.audio                    import Inference\n",
    "from huggingface_hub.hf_api            import HfFolder\n",
    "from pydub.utils                       import mediainfo\n",
    "from pyannote.audio.utils.signal       import Binarize\n",
    "from pyannote.audio.utils.signal       import Peak\n",
    "from pydub                             import AudioSegment\n",
    "from scipy.spatial.distance            import cdist\n",
    "from pyannote.audio                    import Pipeline\n",
    "from tqdm                              import tqdm\n",
    "from pyannote.core                     import notebook\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "import matplotlib.pyplot              as plt\n",
    "import pyannote.audio.pipelines.utils as pyannote_loader\n",
    "import numpy                          as np\n",
    "import soundfile                      as sf\n",
    "import plotly.express                 as px \n",
    "import pandas                         as pd\n",
    "import gradio                         as gr\n",
    "\n",
    "import time\n",
    "import whisper\n",
    "import torch\n",
    "import itertools\n",
    "import librosa\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f45eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_rate(file):\n",
    "    info      = mediainfo(file)\n",
    "    return int(info['sample_rate'])\n",
    "\n",
    "def get_wav_duration(wav_file):    \n",
    "    f = sf.SoundFile(wav_file)\n",
    "    return f.frames / f.samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e948fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_16sr_file(source_path, dest_path):\n",
    "    \n",
    "    speech, sr = librosa.load(source_path, sr=16000)\n",
    "    sf.write(dest_path, speech, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c22bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Whisper_Text(whisper_model, audio):\n",
    "    \n",
    "    # load audio and pad/trim it to fit 30 seconds    \n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel   = whisper.log_mel_spectrogram(audio).to(whisper_model.device)\n",
    "\n",
    "    # decode the audio\n",
    "    #options = whisper.DecodingOptions(language = 'he', beam_size=8, fp16 = False) \n",
    "    options = whisper.DecodingOptions(language = 'en', beam_size=5, fp16 = False) \n",
    "    result  = whisper.decode(whisper_model, mel, options)\n",
    "    result  = result.text\n",
    "    #result  = HebrewNormalizer(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c052ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_TOKEN   = \"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\"\n",
    "HfFolder.save_token(MY_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12828242",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "SAMPLE_WAV  = \"/home/amitli/Datasets/SpkeakerSegmentation/amit_tv.wav\"\n",
    "SAMPLE_WAV  = \"/home/amitli/Datasets/shiri_and_amit.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af408347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert_to_16sr_file(SAMPLE_WAV, SAMPLE_WAV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04507e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sample_rate(SAMPLE_WAV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"base\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c881c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_pipeline   = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b16814b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 45s, sys: 35.3 s, total: 4min 20s\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "diarization = sd_pipeline(SAMPLE_WAV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e190a1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyannote.core.annotation.Annotation"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44113727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/home/amitli/Downloads/test.rttm\", 'w') as file:\n",
    "#     diarization.write_rttm(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b70fbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.core import Annotation\n",
    "with open(\"/home/amitli/Downloads/test.rttm\", 'r') as f:\n",
    "    an = Annotation(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "067544af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7fbfedb0a040>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295777e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wav_duration(SAMPLE_WAV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb142f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech, sr  = librosa.load(SAMPLE_WAV, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970dd4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_speakers_samples = []\n",
    "l_text             = []\n",
    "l_speaker          = []\n",
    "\n",
    "for turn, _, speaker in tqdm(diarization.itertracks(yield_label=True)):        \n",
    "    start_time = turn.start\n",
    "    end_time   = turn.end\n",
    "    duration   = end_time - start_time\n",
    "    if duration < 0.1:\n",
    "        continue\n",
    "        \n",
    "    start_sample    = int(start_time*SAMPLE_RATE)\n",
    "    end_sample      = int(end_time*SAMPLE_RATE)\n",
    "    speaker_samples = speech[start_sample:end_sample]\n",
    "    text            = Get_Whisper_Text(whisper_model, speaker_samples)\n",
    "    l_speakers_samples.append(speaker_samples)\n",
    "    l_speaker.append(speaker)\n",
    "    l_text.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(l_text, l_speaker):\n",
    "    \n",
    "    #speaker = [\"Rit\"]\n",
    "    align        = \"left\" #\"right\"\n",
    "    text_results = \"\"\n",
    "    speaker_dict = {}\n",
    "    colors       = [\"red\", \"green\", \"blue\"]\n",
    "    for i, sp in enumerate(set(l_speaker)):\n",
    "        speaker_dict[sp] = colors[i]\n",
    "        \n",
    "    for i in range(len(l_speaker)): \n",
    "        current_text = f\"<p style='color:{speaker_dict[l_speaker[i]]}; text-align:{align};'> {l_speaker[i]} {l_text[i]} </p>\" + \"\\n\"        \n",
    "        text_results = text_results + current_text\n",
    "    return text_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c009560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI\n",
    "# app = FastAPI()\n",
    "# @app.get(\"/\")\n",
    "\n",
    "g = 0\n",
    "def schedule_job():\n",
    "    global g\n",
    "    g = g + 1\n",
    "    #time.sleep(12)\n",
    "    return f\"g = {g}\"    \n",
    "    \n",
    "def transcribe(audio_file):           \n",
    "    print(audio_file)\n",
    "    diar_text  = prepare_text(l_text, l_speaker)\n",
    "    \n",
    "    figure, ax = plt.subplots()\n",
    "    res        = notebook.plot_annotation(diarization, ax=ax, time=True, legend=True)\n",
    "    \n",
    "    unit_test = get_wav_duration(audio_file)\n",
    "    return unit_test, diar_text, figure\n",
    "\n",
    "\n",
    "def handle_stream(stream_file):    \n",
    "    print(stream_file)\n",
    "    \n",
    "with gr.Blocks(theme=gr.themes.Glass()) as demo:\n",
    "    \n",
    "    with gr.Tab(\"Input From File\"):\n",
    "        input_file  = gr.Audio(source=\"upload\", type=\"filepath\")\n",
    "        run_btn_1   = gr.Button(\"Run\")\n",
    "        \n",
    "    with gr.Tab(\"Input From microphone\"):\n",
    "        intput_rec  = gr.Audio(source=\"microphone\", type=\"filepath\")\n",
    "        #intput_rec  = gr.Audio(source=\"microphone\", type=\"filepath\", streaming=True)\n",
    "        run_btn_2   = gr.Button(\"Run\")\n",
    "        \n",
    "    with gr.Tab(\"Unit Test\"):        \n",
    "        output_ut = gr.Textbox()\n",
    "        \n",
    "    with gr.Tab(\"Whisper\"):        \n",
    "        output_text = gr.outputs.HTML(label=\"\")   \n",
    "        \n",
    "    with gr.Tab(\"Plots\"):\n",
    "        output_img  = gr.Plot()\n",
    "        \n",
    "    with gr.Tab(\"About\"):\n",
    "        gr.Label(\"Version 1\")\n",
    "        \n",
    "    run_btn_1.click(fn=transcribe, inputs=input_file, outputs=[output_ut, output_text, output_img])\n",
    "    run_btn_2.click(fn=transcribe, inputs=intput_rec, outputs=[output_ut, output_text, output_img])   \n",
    "    #run_btn_2.click(fn=handle_stream, inputs=intput_rec, outputs=None)   \n",
    "    dep = demo.load(schedule_job, None, output_ut, every=1)\n",
    "    #period.change(get_plot, period, plot, every=1, cancels=[dep])\n",
    "    \n",
    "#demo.launch()\n",
    "demo.queue().launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a4ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
