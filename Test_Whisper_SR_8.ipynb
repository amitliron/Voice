{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262a482c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53a1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cea8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os                import walk\n",
    "from pydub             import AudioSegment\n",
    "from pydub.utils       import get_array_type\n",
    "from pydub.utils       import mediainfo\n",
    "from pydub.silence     import split_on_silence\n",
    "from datasets          import load_dataset\n",
    "from torchaudio.utils  import download_asset\n",
    "from scipy             import signal\n",
    "from scipy.io          import wavfile\n",
    "from matplotlib.pyplot import figure\n",
    "from tqdm              import tqdm\n",
    "from os                import listdir\n",
    "from os.path           import isfile, join\n",
    "from datetime          import datetime\n",
    "from pyctcdecode       import build_ctcdecoder\n",
    "from pprint            import pprint\n",
    "from torch.utils.data  import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import soundfile         as sf\n",
    "\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import whisper\n",
    "import git\n",
    "import os\n",
    "import jiwer\n",
    "import IPython\n",
    "import array\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9db2416",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> <a id='pipeline_cell'></a> Utils </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079eec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_16sr_file(source_path, dest_path):    \n",
    "    speech, sr = librosa.load(source_path, sr=16000)\n",
    "    sf.write(dest_path, speech, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8330eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_8sr_file(source_path, dest_path):    \n",
    "    speech, sr = librosa.load(source_path, sr=8000)\n",
    "    sf.write(dest_path, speech, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221b4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_rate(file):\n",
    "    info          = mediainfo(file)\n",
    "    sampling_rate = info['sample_rate']\n",
    "    sampling_rate = int(sampling_rate)\n",
    "    return sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e523fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HebrewNormalizer(hebrew_text):\n",
    "    # --- step 1: remove sign characters\n",
    "    #\n",
    "    # ignore_characters = \",~!@#%^&*()-+/|<>[]*'?.{}\"\n",
    "    # for character in ignore_characters:\n",
    "    #     hebrew_text = hebrew_text.replace(character, '')\n",
    "\n",
    "        # --- step 2: replace signs\n",
    "    hebrew_text = hebrew_text.replace('$', \" דולר\")\n",
    "    hebrew_text = hebrew_text.replace('₪', \" שח\")\n",
    "    hebrew_text = hebrew_text.replace('€', \" יורו\")\n",
    "    # hebrew_text = hebrew_text.replace('.', \" נקודה\")\n",
    "    hebrew_text = hebrew_text.replace('ת\"א', \"תל אביב\")\n",
    "    hebrew_text = hebrew_text.replace('ב\"ש', \"באר שבע\")\n",
    "    hebrew_text = hebrew_text.replace('ע\"י', \"על ידי\")\n",
    "    hebrew_text = hebrew_text.replace('אח\"כ', \"אחר כך\")\n",
    "    hebrew_text = hebrew_text.replace('\\\"', \"\")\n",
    "\n",
    "    # for now we will not handle digits, we will have to handle digits if it costs us in the performance of the model\n",
    "    # TODO: handle dates: 3/7 -> third of july\n",
    "    # # --- step 3: replace numbers to words\n",
    "    # dict_nums = {\n",
    "    #     \"0\": \"אפס\",\n",
    "    #     \"1\": \"אחד\",\n",
    "    #     \"2\": \"שתיים\",\n",
    "    #     \"3\": \"שלוש\",\n",
    "    #     \"4\": \"ארבע\",\n",
    "    #     \"5\": \"חמש\",\n",
    "    #     \"6\": \"שש\",\n",
    "    #     \"7\": \"שבע\",\n",
    "    #     \"8\": \"שמונה\",\n",
    "    #     \"9\": \"תשע\",\n",
    "    #     \"10\": \"עשר\",\n",
    "    # }\n",
    "    # for digit, word in dict_nums.items():\n",
    "    #     hebrew_text = hebrew_text.replace(digit, word)\n",
    "    #\n",
    "    # # --- step 4: replace female numbers to male numbers\n",
    "    # dict_male = {\n",
    "    #     \"אחת\": \"אחד\",\n",
    "    #     \"שתיים\": \"שניים\",\n",
    "    #     \"שלושה\": \"שלוש\",\n",
    "    #     \"ארבעה\": \"ארבע\",\n",
    "    #     \"חמישה\": \"חמש\",\n",
    "    #     \"שישה\": \"שש\",\n",
    "    #     \"שבעה\": \"שבע\",\n",
    "    #     \"תשעה\": \"תשע\",\n",
    "    #\n",
    "    # }\n",
    "    # for female, male in dict_male.items():\n",
    "    #     hebrew_text = hebrew_text.replace(female, male)\n",
    "    # postproccessing, removing special charcteres after handling and translating them\n",
    "    valid_tokens = \"פ ם ן ו ט א ר ק ף ך ל ח י ע כ ג ד ש ץ ת צ מ נ ה ב ס ז 1 2 3 4 5 6 7 8 9 0\"\n",
    "    valid_tokens = set([x.lower() for x in valid_tokens])\n",
    "    # The caret in the character class ([^) means match anything but\n",
    "    invalid_chars_regex = f\"[^\\s{re.escape(''.join(set(valid_tokens)))}]\"\n",
    "\n",
    "\n",
    "    \"\"\" DO ADAPT FOR YOUR USE CASE. this function normalizes the target text. \"\"\"\n",
    "    hebrew_text = re.sub(invalid_chars_regex, \" \", hebrew_text)\n",
    "    hebrew_text = re.sub(\"\\s+\", \" \", hebrew_text).strip()\n",
    "    # --- return result\n",
    "    return hebrew_text    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de42c86",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Preprocessing </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c90de05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8009a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBO_SOURCE  = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/wavs/\"\n",
    "ROBO_SR_16   = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_16K/\"\n",
    "ROBO_SR_8    = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K/\"\n",
    "ROBO_SR_8_16 = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K_16k/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86c831e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_file_name      = [entry for entry in os.listdir(ROBO_SR_8) if os.path.isfile(os.path.join(ROBO_SR_8, entry))]\n",
    "# for file_name in tqdm(list_file_name):\n",
    "\n",
    "#         full_file_name = f\"{ROBO_SR_8}/{file_name}\"\n",
    "#         full_sr_16     = f\"{ROBO_SR_8_16}/{file_name}\" \n",
    "#         convert_to_16sr_file(full_file_name, full_sr_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd3d06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [15:33<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "convert = False\n",
    "\n",
    "if convert is True:\n",
    "    list_file_name      = [entry for entry in os.listdir(ROBO_SOURCE) if os.path.isfile(os.path.join(ROBO_SOURCE, entry))]\n",
    "\n",
    "    for file_name in tqdm(list_file_name):\n",
    "\n",
    "        full_file_name = f\"{ROBO_SOURCE}/{file_name}\"\n",
    "        full_sr_16     = f\"{ROBO_SR_16}/{file_name}\"\n",
    "        full_sr_8      = f\"{ROBO_SR_8}/{file_name}\"\n",
    "\n",
    "        current_sr     = get_sample_rate(full_file_name)\n",
    "        if 44100 != current_sr:\n",
    "            print(f\"Source Sample Rate: {current_sr}\")\n",
    "            continue\n",
    "\n",
    "        convert_to_16sr_file(full_file_name, full_sr_16)\n",
    "        convert_to_8sr_file(full_file_name, full_sr_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5e0d0c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ׁ'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_gt_file = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/metadata_full.csv\"\n",
    "#csv_gt_file = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/metadata.csv\"\n",
    "df_meta     = pd.read_csv(csv_gt_file, \n",
    "                      sep=\"|\",\n",
    "                         encoding=\"utf-8\")#, \n",
    "                      #names=[\"file\", \"gt\", \"gt2\"], header=None)\n",
    "\n",
    "df_meta[\"transcript\"].values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4922a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>source_file_audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gold_000_line_000</td>\n",
       "      <td>שָׁלוֹם, צְלִיל אַבְרָהָם.</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gold_000_line_001</td>\n",
       "      <td>לְגַמְרֵי, מַדְהִים, לֹא?</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gold_000_line_002</td>\n",
       "      <td>וְדַוְוקָא בִּגְלַל שֶׁכּוּלָּנוּ הָיִינוּ עֲס...</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gold_000_line_003</td>\n",
       "      <td>אָז הַיּוֹם אֲנַחְנוּ נְדַבֵּר עַל הַחֲקִירָה ...</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gold_000_line_004</td>\n",
       "      <td>הָרָמַת מָסַךְ מֵעַל סְבַךְ שֶׁל אִינְטֶרֶסִים...</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_id                                         transcript  \\\n",
       "0  gold_000_line_000                         שָׁלוֹם, צְלִיל אַבְרָהָם.   \n",
       "1  gold_000_line_001                          לְגַמְרֵי, מַדְהִים, לֹא?   \n",
       "2  gold_000_line_002  וְדַוְוקָא בִּגְלַל שֶׁכּוּלָּנוּ הָיִינוּ עֲס...   \n",
       "3  gold_000_line_003  אָז הַיּוֹם אֲנַחְנוּ נְדַבֵּר עַל הַחֲקִירָה ...   \n",
       "4  gold_000_line_004  הָרָמַת מָסַךְ מֵעַל סְבַךְ שֶׁל אִינְטֶרֶסִים...   \n",
       "\n",
       "  source_file_audio  \n",
       "0  4000_2_shaul.mp3  \n",
       "1  4000_2_shaul.mp3  \n",
       "2  4000_2_shaul.mp3  \n",
       "3  4000_2_shaul.mp3  \n",
       "4  4000_2_shaul.mp3  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "770cf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoboshaulGoldDataset(Dataset):\n",
    "        \n",
    "    def __init__(self, source_folder, df_gt, device):        \n",
    "        \n",
    "        self.list_file_names = [entry for entry in os.listdir(ROBO_SOURCE) if os.path.isfile(os.path.join(ROBO_SOURCE, entry))]        \n",
    "        self.l_file_name     = []\n",
    "        self.l_full_path     = []\n",
    "        self.l_gt            = []\n",
    "        self.device          = device\n",
    "        \n",
    "        for file_name in tqdm(list_file_name):\n",
    "\n",
    "            # --- get GT text            \n",
    "            gt         = df_gt[df_gt['file'] == file_name[:-4]]['gt'].values[0]            \n",
    "            full_src   = f\"{source_folder}/{file_name}\"       \n",
    "            \n",
    "            self.l_file_name.append(file_name)\n",
    "            self.l_full_path.append(full_src)                \n",
    "            self.l_gt.append(gt)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l_gt)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        audio_file_path = self.l_full_path[idx]        \n",
    "        audio           = whisper.load_audio(str(audio_file_path))\n",
    "        audio           = whisper.pad_or_trim(audio)\n",
    "        \n",
    "        mel             = whisper.log_mel_spectrogram(audio).to(self.device)        \n",
    "        \n",
    "        sample          = {'mel':      mel, \n",
    "                          'text':      HebrewNormalizer(self.l_gt[idx]), \n",
    "                          'file':      self.l_file_name[idx],                          \n",
    "                          'full_path': self.l_full_path[idx]}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "907587f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_whisper_on_rambo(loader, res_file_name, lang):\n",
    "    df = pd.DataFrame()\n",
    "    for batch in tqdm(loader):\n",
    "        \n",
    "        languages        = []\n",
    "        if lang is not None:\n",
    "            languages = [lang]        \n",
    "        mel              = batch['mel']\n",
    "        audio_data       = {'wav': json.dumps(mel.tolist()), 'languages': languages}\n",
    "        gt               = batch['text']\n",
    "\n",
    "        #res              = requests.get('http://10.53.140.33:80/batch_inference/', json=audio_data)\n",
    "        res              = requests.get('http://10.53.140.33:80/batch_inference_beam/', json=audio_data)\n",
    "        res_list         = res.json()[0]\n",
    "\n",
    "        l_wer            = []\n",
    "        l_whisper        = []    \n",
    "        l_res_lang       = []\n",
    "        l_avg_logprob    = []\n",
    "        l_no_speech_prob = []\n",
    "        l_compres_ratio  = []\n",
    "\n",
    "        for i, res in enumerate(res_list):\n",
    "            whisper_text = res['text']\n",
    "            whisper_text = HebrewNormalizer(whisper_text)\n",
    "            l_whisper.append(whisper_text)                \n",
    "            if whisper_text == '':\n",
    "                l_wer.append(1)\n",
    "            else:\n",
    "                l_wer.append(jiwer.wer(whisper_text, gt[i]))\n",
    "            l_res_lang.append(res['language'])\n",
    "            l_avg_logprob.append(res['avg_logprob'])\n",
    "            l_no_speech_prob.append(res['no_speech_prob'])\n",
    "            l_compres_ratio.append(res['compression_ratio'])\n",
    "\n",
    "\n",
    "        df_tmp     = pd.DataFrame({\n",
    "            \"whisper\":           l_whisper,\n",
    "            \"gt\":                gt,\n",
    "            \"wer\":               l_wer,\n",
    "            \"file\":              batch['file'],            \n",
    "            \"full_path\":         batch['full_path'],\n",
    "            \"detect_lang\":       l_res_lang,\n",
    "            \"avg_logprob\":       l_avg_logprob,\n",
    "            \"no_speech_prob\":    l_no_speech_prob,\n",
    "            \"compression_ratio\": l_compres_ratio,\n",
    "\n",
    "        })\n",
    "        df = pd.concat([df, df_tmp], ignore_index=True)        \n",
    "        df.to_csv(res_file_name)\n",
    "        \n",
    "            \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e17bd",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Test With SR=16K </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d489b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [00:00<00:00, 3012.24it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_16k = RoboshaulGoldDataset(source_folder = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_16K\",\n",
    "                               df_gt         = df_meta,\n",
    "                               device        = DEVICE)\n",
    "\n",
    "loader_16k = DataLoader(dataset_16k, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b838a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [2:23:34<00:00, 57.43s/it]\n"
     ]
    }
   ],
   "source": [
    "run_whisper_on_sr_16 = False\n",
    "if run_whisper_on_sr_16 is True:\n",
    "    run_whisper_on_rambo(loader_16k,\n",
    "                         \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_16k.csv\", \n",
    "                         None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e624fd8",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Test With SR=8K </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "611f1d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [00:00<00:00, 3055.32it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_8k = RoboshaulGoldDataset(source_folder = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K\",\n",
    "                               df_gt         = df_meta,\n",
    "                               device        = DEVICE)\n",
    "\n",
    "loader_8k = DataLoader(dataset_8k, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c6c8b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [2:25:55<00:00, 58.37s/it]\n"
     ]
    }
   ],
   "source": [
    "run_whisper_on_sr_8 = False\n",
    "if run_whisper_on_sr_8 is True:\n",
    "    run_whisper_on_rambo(loader_8k, \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k.csv\", \n",
    "                         None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9529cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [00:01<00:00, 2951.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_8_16k = RoboshaulGoldDataset(\n",
    "source_folder = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K_16k/\",\n",
    "                           df_gt         = df_meta,\n",
    "                           device        = DEVICE)\n",
    "\n",
    "loader_8_16k = DataLoader(dataset_8_16k, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c36cef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_whisper_on_sr_8_16 = False\n",
    "\n",
    "if run_whisper_on_sr_8_16 is True:\n",
    "    run_whisper_on_rambo(loader_8_16k,\n",
    "                         \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k_16k.csv\", \n",
    "                         None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88ce98",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Compare Results </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "afcc5b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2986, 10), (2986, 10), (2986, 10))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8    = pd.read_csv(\"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k.csv\")\n",
    "df_16   = pd.read_csv(\"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_16k.csv\")\n",
    "df_8_16 = pd.read_csv(\"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k_16k.csv\")\n",
    "\n",
    "df_8.shape, df_16.shape, df_8_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b27c4df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 53, 55)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_8[df_8['detect_lang'] != 'he']), len(df_16[df_16['detect_lang'] != 'he']),  len(df_8_16[df_8_16['detect_lang'] != 'he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94750dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ל'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta['gt'].values[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4019236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ב כ מ ע ט ש נ ת י ים ש ח ל פו מ א ז ש ה ק ו רו...\n",
       "1       א נ י ב א מ ת ל א יו ד ע א ם נ ת נ י הו עו מ ד...\n",
       "2        א נ ח נו פ ש ו ט נ ש ק יע ב כו ל ם ב כ ל ה ש ו ק\n",
       "3       ו ג ם ה עו ב ד ה ש א נ ח נו ו גו פ ים א ח ר ים...\n",
       "4       א ם ת ש נ ו א ת ה ה נ חו ת ש ל ה מ ו ד ל ת ש נ...\n",
       "                              ...                        \n",
       "2981    ה א ם א נ ח נו ב תו ך ס ע ר ה ש ל ע ל י י ת מ ...\n",
       "2982    ש ית ו ף פ עו ל ה ש ה או א י ס י ד י הו ב יל ב...\n",
       "2983    ו ה י ו ם א נ ח נו עו מ ד ים ל ח ט ט ב א ח ד ה...\n",
       "2984    ו כ ש ב ת י ה חו ל ים נ כ נ ס ים ל ג יר עו נו ...\n",
       "2985    ה ת יק ה ז ה ש ש ל ב ה הו כ חו ת ש ל ו ה ת ח י...\n",
       "Name: gt, Length: 2986, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8['gt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
