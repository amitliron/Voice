{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bdf8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cff4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "66d1b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os                import walk\n",
    "from pydub             import AudioSegment\n",
    "from pydub.utils       import get_array_type\n",
    "from pydub.utils       import mediainfo\n",
    "from pydub.silence     import split_on_silence\n",
    "from datasets          import load_dataset\n",
    "from torchaudio.utils  import download_asset\n",
    "from scipy             import signal\n",
    "from scipy.io          import wavfile\n",
    "from matplotlib.pyplot import figure\n",
    "from tqdm              import tqdm\n",
    "from os                import listdir\n",
    "from os.path           import isfile, join\n",
    "from datetime          import datetime\n",
    "from pyctcdecode       import build_ctcdecoder\n",
    "from pprint            import pprint\n",
    "from torch.utils.data  import Dataset, DataLoader\n",
    "from hebrew            import Hebrew\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import soundfile         as sf\n",
    "\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import whisper\n",
    "import git\n",
    "import os\n",
    "import jiwer\n",
    "import IPython\n",
    "import array\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715927f",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> <a id='pipeline_cell'></a> Utils </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2110fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_16sr_file(source_path, dest_path):    \n",
    "    speech, sr = librosa.load(source_path, sr=16000)\n",
    "    sf.write(dest_path, speech, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c915f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_8sr_file(source_path, dest_path):    \n",
    "    speech, sr = librosa.load(source_path, sr=8000)\n",
    "    sf.write(dest_path, speech, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c89790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_rate(file):\n",
    "    info          = mediainfo(file)\n",
    "    sampling_rate = info['sample_rate']\n",
    "    sampling_rate = int(sampling_rate)\n",
    "    return sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "06785bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RoboSoul_GT_HebrewNormalizer(hebrew_text):\n",
    "    \n",
    "    # --- step 2: replace signs\n",
    "    hebrew_text = hebrew_text.replace('$', \" דולר\")\n",
    "    hebrew_text = hebrew_text.replace('₪', \" שח\")\n",
    "    hebrew_text = hebrew_text.replace('€', \" יורו\")\n",
    "    \n",
    "    # hebrew_text = hebrew_text.replace('.', \" נקודה\")\n",
    "    hebrew_text = hebrew_text.replace('ת\"א', \"תל אביב\")\n",
    "    hebrew_text = hebrew_text.replace('ב\"ש', \"באר שבע\")\n",
    "    hebrew_text = hebrew_text.replace('ע\"י', \"על ידי\")\n",
    "    hebrew_text = hebrew_text.replace('אח\"כ', \"אחר כך\")\n",
    "    hebrew_text = hebrew_text.replace('\\\"', \"\")\n",
    "\n",
    "    # postproccessing, removing special charcteres after handling and translating them\n",
    "    valid_tokens = \"פ ם ן ו ט א ר ק ף ך ל ח י ע כ ג ד ש ץ ת צ מ נ ה ב ס ז 1 2 3 4 5 6 7 8 9 0 \"\n",
    "    valid_tokens = set([x.lower() for x in valid_tokens])    \n",
    "        \n",
    "    res = \"\"      \n",
    "    for i in range(len(hebrew_text)):\n",
    "        letter = hebrew_text[i]        \n",
    "        if letter in valid_tokens:\n",
    "            res = res + letter\n",
    "    return res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b2b4aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HebrewNormalizer(hebrew_text):\n",
    "    # --- step 1: remove sign characters\n",
    "    #\n",
    "    # ignore_characters = \",~!@#%^&*()-+/|<>[]*'?.{}\"\n",
    "    # for character in ignore_characters:\n",
    "    #     hebrew_text = hebrew_text.replace(character, '')\n",
    "\n",
    "        # --- step 2: replace signs\n",
    "    hebrew_text = hebrew_text.replace('$', \" דולר\")\n",
    "    hebrew_text = hebrew_text.replace('₪', \" שח\")\n",
    "    hebrew_text = hebrew_text.replace('€', \" יורו\")\n",
    "    # hebrew_text = hebrew_text.replace('.', \" נקודה\")\n",
    "    hebrew_text = hebrew_text.replace('ת\"א', \"תל אביב\")\n",
    "    hebrew_text = hebrew_text.replace('ב\"ש', \"באר שבע\")\n",
    "    hebrew_text = hebrew_text.replace('ע\"י', \"על ידי\")\n",
    "    hebrew_text = hebrew_text.replace('אח\"כ', \"אחר כך\")\n",
    "    hebrew_text = hebrew_text.replace('\\\"', \"\")\n",
    "\n",
    "    # for now we will not handle digits, we will have to handle digits if it costs us in the performance of the model\n",
    "    # TODO: handle dates: 3/7 -> third of july\n",
    "    # # --- step 3: replace numbers to words\n",
    "    # dict_nums = {\n",
    "    #     \"0\": \"אפס\",\n",
    "    #     \"1\": \"אחד\",\n",
    "    #     \"2\": \"שתיים\",\n",
    "    #     \"3\": \"שלוש\",\n",
    "    #     \"4\": \"ארבע\",\n",
    "    #     \"5\": \"חמש\",\n",
    "    #     \"6\": \"שש\",\n",
    "    #     \"7\": \"שבע\",\n",
    "    #     \"8\": \"שמונה\",\n",
    "    #     \"9\": \"תשע\",\n",
    "    #     \"10\": \"עשר\",\n",
    "    # }\n",
    "    # for digit, word in dict_nums.items():\n",
    "    #     hebrew_text = hebrew_text.replace(digit, word)\n",
    "    #\n",
    "    # # --- step 4: replace female numbers to male numbers\n",
    "    # dict_male = {\n",
    "    #     \"אחת\": \"אחד\",\n",
    "    #     \"שתיים\": \"שניים\",\n",
    "    #     \"שלושה\": \"שלוש\",\n",
    "    #     \"ארבעה\": \"ארבע\",\n",
    "    #     \"חמישה\": \"חמש\",\n",
    "    #     \"שישה\": \"שש\",\n",
    "    #     \"שבעה\": \"שבע\",\n",
    "    #     \"תשעה\": \"תשע\",\n",
    "    #\n",
    "    # }\n",
    "    # for female, male in dict_male.items():\n",
    "    #     hebrew_text = hebrew_text.replace(female, male)\n",
    "    # postproccessing, removing special charcteres after handling and translating them\n",
    "    valid_tokens = \"פ ם ן ו ט א ר ק ף ך ל ח י ע כ ג ד ש ץ ת צ מ נ ה ב ס ז 1 2 3 4 5 6 7 8 9 0  \"\n",
    "    valid_tokens = set([x.lower() for x in valid_tokens])\n",
    "    # The caret in the character class ([^) means match anything but\n",
    "    invalid_chars_regex = f\"[^\\s{re.escape(''.join(set(valid_tokens)))}]\"\n",
    "\n",
    "\n",
    "    \"\"\" DO ADAPT FOR YOUR USE CASE. this function normalizes the target text. \"\"\"\n",
    "    hebrew_text = re.sub(invalid_chars_regex, \" \", hebrew_text)\n",
    "    hebrew_text = re.sub(\"\\s+\", \" \", hebrew_text).strip()\n",
    "    # --- return result\n",
    "    return hebrew_text    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5857a2",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Preprocessing </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817af47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5b48f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBO_SOURCE  = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/wavs/\"\n",
    "ROBO_SR_16   = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_16K/\"\n",
    "ROBO_SR_8    = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K/\"\n",
    "ROBO_SR_8_16 = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K_16k/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b7ae057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_file_name      = [entry for entry in os.listdir(ROBO_SR_8) if os.path.isfile(os.path.join(ROBO_SR_8, entry))]\n",
    "# for file_name in tqdm(list_file_name):\n",
    "\n",
    "#         full_file_name = f\"{ROBO_SR_8}/{file_name}\"\n",
    "#         full_sr_16     = f\"{ROBO_SR_8_16}/{file_name}\" \n",
    "#         convert_to_16sr_file(full_file_name, full_sr_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ded84e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [15:33<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "convert = False\n",
    "\n",
    "if convert is True:\n",
    "    list_file_name      = [entry for entry in os.listdir(ROBO_SOURCE) if os.path.isfile(os.path.join(ROBO_SOURCE, entry))]\n",
    "\n",
    "    for file_name in tqdm(list_file_name):\n",
    "\n",
    "        full_file_name = f\"{ROBO_SOURCE}/{file_name}\"\n",
    "        full_sr_16     = f\"{ROBO_SR_16}/{file_name}\"\n",
    "        full_sr_8      = f\"{ROBO_SR_8}/{file_name}\"\n",
    "\n",
    "        current_sr     = get_sample_rate(full_file_name)\n",
    "        if 44100 != current_sr:\n",
    "            print(f\"Source Sample Rate: {current_sr}\")\n",
    "            continue\n",
    "\n",
    "        convert_to_16sr_file(full_file_name, full_sr_16)\n",
    "        convert_to_8sr_file(full_file_name, full_sr_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "134f1aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>source_file_audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gold_000_line_000</td>\n",
       "      <td>שלום צליל אברהם</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gold_000_line_001</td>\n",
       "      <td>לגמרי מדהים לא</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gold_000_line_002</td>\n",
       "      <td>ודווקא בגלל שכולנו היינו עסוקים במלחמה הפודקאס...</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gold_000_line_003</td>\n",
       "      <td>אז היום אנחנו נדבר על החקירה הנגדית של אילן יש...</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gold_000_line_004</td>\n",
       "      <td>הרמת מסך מעל סבך של אינטרסים בעולם התקשורת היש...</td>\n",
       "      <td>4000_2_shaul.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_id                                         transcript  \\\n",
       "0  gold_000_line_000                                    שלום צליל אברהם   \n",
       "1  gold_000_line_001                                     לגמרי מדהים לא   \n",
       "2  gold_000_line_002  ודווקא בגלל שכולנו היינו עסוקים במלחמה הפודקאס...   \n",
       "3  gold_000_line_003  אז היום אנחנו נדבר על החקירה הנגדית של אילן יש...   \n",
       "4  gold_000_line_004  הרמת מסך מעל סבך של אינטרסים בעולם התקשורת היש...   \n",
       "\n",
       "  source_file_audio  \n",
       "0  4000_2_shaul.mp3  \n",
       "1  4000_2_shaul.mp3  \n",
       "2  4000_2_shaul.mp3  \n",
       "3  4000_2_shaul.mp3  \n",
       "4  4000_2_shaul.mp3  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_gt_file = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/metadata_full.csv\"\n",
    "df_meta     = pd.read_csv(csv_gt_file, \n",
    "                          sep=\"|\",\n",
    "                          encoding=\"utf-8\")\n",
    "for i in range(len(df_meta)):    \n",
    "    df_meta['transcript'].values[i] = Hebrew(df_meta['transcript'].values[i]).no_niqqud().string\n",
    "    df_meta['transcript'].values[i] = HebrewNormalizer(df_meta['transcript'].values[i])\n",
    "        \n",
    "df_meta.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31edff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ec2e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoboshaulGoldDataset(Dataset):\n",
    "        \n",
    "    def __init__(self, source_folder, df_gt, device):        \n",
    "        \n",
    "        self.list_file_names = [entry for entry in os.listdir(ROBO_SOURCE) if os.path.isfile(os.path.join(ROBO_SOURCE, entry))]        \n",
    "        self.l_file_name     = []\n",
    "        self.l_full_path     = []\n",
    "        self.l_gt            = []\n",
    "        self.device          = device\n",
    "        \n",
    "        for file_name in tqdm(list_file_name):\n",
    "\n",
    "            # --- get GT text            \n",
    "            gt         = df_gt[df_gt['file'] == file_name[:-4]]['gt'].values[0]            \n",
    "            full_src   = f\"{source_folder}/{file_name}\"       \n",
    "            \n",
    "            self.l_file_name.append(file_name)\n",
    "            self.l_full_path.append(full_src)                \n",
    "            self.l_gt.append(gt)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l_gt)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        audio_file_path = self.l_full_path[idx]        \n",
    "        audio           = whisper.load_audio(str(audio_file_path))\n",
    "        audio           = whisper.pad_or_trim(audio)\n",
    "        \n",
    "        mel             = whisper.log_mel_spectrogram(audio).to(self.device)        \n",
    "        \n",
    "        sample          = {'mel':      mel, \n",
    "                          'text':      HebrewNormalizer(self.l_gt[idx]), \n",
    "                          'file':      self.l_file_name[idx],                          \n",
    "                          'full_path': self.l_full_path[idx]}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5154d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_whisper_on_rambo(loader, res_file_name, lang):\n",
    "    df = pd.DataFrame()\n",
    "    for batch in tqdm(loader):\n",
    "        \n",
    "        languages        = []\n",
    "        if lang is not None:\n",
    "            languages = [lang]        \n",
    "        mel              = batch['mel']\n",
    "        audio_data       = {'wav': json.dumps(mel.tolist()), 'languages': languages}\n",
    "        gt               = batch['text']\n",
    "\n",
    "        #res              = requests.get('http://10.53.140.33:80/batch_inference/', json=audio_data)\n",
    "        res              = requests.get('http://10.53.140.33:80/batch_inference_beam/', json=audio_data)\n",
    "        res_list         = res.json()[0]\n",
    "\n",
    "        l_wer            = []\n",
    "        l_whisper        = []    \n",
    "        l_res_lang       = []\n",
    "        l_avg_logprob    = []\n",
    "        l_no_speech_prob = []\n",
    "        l_compres_ratio  = []\n",
    "\n",
    "        for i, res in enumerate(res_list):\n",
    "            whisper_text = res['text']\n",
    "            whisper_text = HebrewNormalizer(whisper_text)\n",
    "            l_whisper.append(whisper_text)                \n",
    "            if whisper_text == '':\n",
    "                l_wer.append(1)\n",
    "            else:\n",
    "                l_wer.append(jiwer.wer(whisper_text, gt[i]))\n",
    "            l_res_lang.append(res['language'])\n",
    "            l_avg_logprob.append(res['avg_logprob'])\n",
    "            l_no_speech_prob.append(res['no_speech_prob'])\n",
    "            l_compres_ratio.append(res['compression_ratio'])\n",
    "\n",
    "\n",
    "        df_tmp     = pd.DataFrame({\n",
    "            \"whisper\":           l_whisper,\n",
    "            \"gt\":                gt,\n",
    "            \"wer\":               l_wer,\n",
    "            \"file\":              batch['file'],            \n",
    "            \"full_path\":         batch['full_path'],\n",
    "            \"detect_lang\":       l_res_lang,\n",
    "            \"avg_logprob\":       l_avg_logprob,\n",
    "            \"no_speech_prob\":    l_no_speech_prob,\n",
    "            \"compression_ratio\": l_compres_ratio,\n",
    "\n",
    "        })\n",
    "        df = pd.concat([df, df_tmp], ignore_index=True)        \n",
    "        df.to_csv(res_file_name)\n",
    "        \n",
    "            \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556a406",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Test With SR=16K </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04343cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [00:00<00:00, 3012.24it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_16k = RoboshaulGoldDataset(source_folder = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_16K\",\n",
    "                               df_gt         = df_meta,\n",
    "                               device        = DEVICE)\n",
    "\n",
    "loader_16k = DataLoader(dataset_16k, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22946529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [2:23:34<00:00, 57.43s/it]\n"
     ]
    }
   ],
   "source": [
    "run_whisper_on_sr_16 = False\n",
    "if run_whisper_on_sr_16 is True:\n",
    "    run_whisper_on_rambo(loader_16k,\n",
    "                         \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_16k.csv\", \n",
    "                         None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f6cf4",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Test With SR=8K </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20bc8d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [00:00<00:00, 3055.32it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_8k = RoboshaulGoldDataset(source_folder = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K\",\n",
    "                               df_gt         = df_meta,\n",
    "                               device        = DEVICE)\n",
    "\n",
    "loader_8k = DataLoader(dataset_8k, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc4acb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [2:25:55<00:00, 58.37s/it]\n"
     ]
    }
   ],
   "source": [
    "run_whisper_on_sr_8 = False\n",
    "if run_whisper_on_sr_8 is True:\n",
    "    run_whisper_on_rambo(loader_8k, \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k.csv\", \n",
    "                         None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "deefce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [00:01<00:00, 2951.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_8_16k = RoboshaulGoldDataset(\n",
    "source_folder = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K_16k/\",\n",
    "                           df_gt         = df_meta,\n",
    "                           device        = DEVICE)\n",
    "\n",
    "loader_8_16k = DataLoader(dataset_8_16k, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "569b6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_whisper_on_sr_8_16 = False\n",
    "\n",
    "if run_whisper_on_sr_8_16 is True:\n",
    "    run_whisper_on_rambo(loader_8_16k,\n",
    "                         \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k_16k.csv\", \n",
    "                         None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419440d0",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Compare Results </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "848afd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2986, 10), (2986, 10), (2986, 10))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8    = pd.read_csv(\"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k.csv\")\n",
    "df_16   = pd.read_csv(\"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_16k.csv\")\n",
    "df_8_16 = pd.read_csv(\"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k_16k.csv\")\n",
    "\n",
    "df_8.shape, df_16.shape, df_8_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f3f95e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gt_in_results(df_res, df_gt):\n",
    "    \n",
    "    for i in range(len(df_gt)):\n",
    "        file_id     = f\"{df_gt['file_id'].values[i]}.wav\"\n",
    "        correct_gt  = df_gt['transcript'].values[i]\n",
    "            \n",
    "        tmp_df      = df_res[df_res['file'] == file_id]        \n",
    "        wav_file    = tmp_df['file'].values[0]\n",
    "        res_gt      = tmp_df['gt'].values[0]\n",
    "        \n",
    "        if file_id != wav_file:\n",
    "            print(f\"error: GT: {file_id} RES: {wav_file}\")\n",
    "            continue\n",
    "            \n",
    "        index = df_res[df_res['file'] == file_id].index.tolist()\n",
    "        if len(index) != 1:\n",
    "            print(\"More than one index\")\n",
    "        index = index[0]\n",
    "        \n",
    "        df_res['gt'].values[index] = correct_gt\n",
    "                \n",
    "        whisper_text = df_res['whisper'].values[index]\n",
    "        lang         = df_res['detect_lang'].values[index] \n",
    "        \n",
    "        if whisper_text != '':\n",
    "            if lang == \"he\":\n",
    "                res_wer                     = jiwer.wer(whisper_text, correct_gt)            \n",
    "                df_res['wer'].values[index] = res_wer\n",
    "\n",
    "fix_gt_in_results(df_8, df_meta)            \n",
    "fix_gt_in_results(df_16, df_meta)            \n",
    "fix_gt_in_results(df_8_16, df_meta)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9092428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "56512632",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_8_no_hebrew_num    = len(df_8[df_8['detect_lang'] != 'he'])\n",
    "sr_16_no_hebrew_num   = len(df_16[df_16['detect_lang'] != 'he'])\n",
    "sr_8_16_no_hebrew_num = len(df_8_16[df_8_16['detect_lang'] != 'he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "299c0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wer_8_sr        = round(np.mean(df_8['wer'].values), 2)\n",
    "total_wer_16_sr       = round(np.mean(df_16['wer'].values), 2)\n",
    "total_wer_8_16_sr     = round(np.mean(df_8_16['wer'].values), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "685ec184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>SR_8</th>\n",
       "      <th>SR_Read_As16</th>\n",
       "      <th>SR_8_TO_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Count No Hebrew</td>\n",
       "      <td>56.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WER</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Type   SR_8  SR_Read_As16  SR_8_TO_16\n",
       "0  Count No Hebrew  56.00         53.00       55.00\n",
       "1              WER   0.13          0.12        0.13"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results                  = pd.DataFrame()\n",
    "df_results[\"Type\"]          = [\"Count No Hebrew\", \"WER\"]\n",
    "df_results[\"SR_Read_As16\"]          = [sr_8_no_hebrew_num, total_wer_8_sr]\n",
    "df_results[\"SR_16\"]  = [sr_16_no_hebrew_num, total_wer_16_sr]\n",
    "df_results[\"SR_8_TO_16\"]    = [sr_8_16_no_hebrew_num, total_wer_8_16_sr]\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ccb0b2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2986"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "99ad950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_8[df_8['detect_lang'] != 'he']['full_path'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
