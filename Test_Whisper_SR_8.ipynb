{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8548f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4234b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f39563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os                import walk\n",
    "from pydub             import AudioSegment\n",
    "from pydub.utils       import get_array_type\n",
    "from pydub.utils       import mediainfo\n",
    "from pydub.silence     import split_on_silence\n",
    "from datasets          import load_dataset\n",
    "from torchaudio.utils  import download_asset\n",
    "from scipy             import signal\n",
    "from scipy.io          import wavfile\n",
    "from matplotlib.pyplot import figure\n",
    "from tqdm              import tqdm\n",
    "from os                import listdir\n",
    "from os.path           import isfile, join\n",
    "from datetime          import datetime\n",
    "from pyctcdecode       import build_ctcdecoder\n",
    "from pprint            import pprint\n",
    "from torch.utils.data  import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import soundfile         as sf\n",
    "\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import whisper\n",
    "import git\n",
    "import os\n",
    "import jiwer\n",
    "import IPython\n",
    "import array\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d02883a",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> <a id='pipeline_cell'></a> Utils </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5cb4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_16sr_file(source_path, dest_path):    \n",
    "    speech, sr = librosa.load(source_path, sr=16000)\n",
    "    sf.write(dest_path, speech, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5085710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_8sr_file(source_path, dest_path):    \n",
    "    speech, sr = librosa.load(source_path, sr=8000)\n",
    "    sf.write(dest_path, speech, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede280b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_rate(file):\n",
    "    info          = mediainfo(file)\n",
    "    sampling_rate = info['sample_rate']\n",
    "    sampling_rate = int(sampling_rate)\n",
    "    return sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4813f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HebrewNormalizer(hebrew_text):\n",
    "    # --- step 1: remove sign characters\n",
    "    #\n",
    "    # ignore_characters = \",~!@#%^&*()-+/|<>[]*'?.{}\"\n",
    "    # for character in ignore_characters:\n",
    "    #     hebrew_text = hebrew_text.replace(character, '')\n",
    "\n",
    "        # --- step 2: replace signs\n",
    "    hebrew_text = hebrew_text.replace('$', \" דולר\")\n",
    "    hebrew_text = hebrew_text.replace('₪', \" שח\")\n",
    "    hebrew_text = hebrew_text.replace('€', \" יורו\")\n",
    "    # hebrew_text = hebrew_text.replace('.', \" נקודה\")\n",
    "    hebrew_text = hebrew_text.replace('ת\"א', \"תל אביב\")\n",
    "    hebrew_text = hebrew_text.replace('ב\"ש', \"באר שבע\")\n",
    "    hebrew_text = hebrew_text.replace('ע\"י', \"על ידי\")\n",
    "    hebrew_text = hebrew_text.replace('אח\"כ', \"אחר כך\")\n",
    "    hebrew_text = hebrew_text.replace('\\\"', \"\")\n",
    "\n",
    "    # for now we will not handle digits, we will have to handle digits if it costs us in the performance of the model\n",
    "    # TODO: handle dates: 3/7 -> third of july\n",
    "    # # --- step 3: replace numbers to words\n",
    "    # dict_nums = {\n",
    "    #     \"0\": \"אפס\",\n",
    "    #     \"1\": \"אחד\",\n",
    "    #     \"2\": \"שתיים\",\n",
    "    #     \"3\": \"שלוש\",\n",
    "    #     \"4\": \"ארבע\",\n",
    "    #     \"5\": \"חמש\",\n",
    "    #     \"6\": \"שש\",\n",
    "    #     \"7\": \"שבע\",\n",
    "    #     \"8\": \"שמונה\",\n",
    "    #     \"9\": \"תשע\",\n",
    "    #     \"10\": \"עשר\",\n",
    "    # }\n",
    "    # for digit, word in dict_nums.items():\n",
    "    #     hebrew_text = hebrew_text.replace(digit, word)\n",
    "    #\n",
    "    # # --- step 4: replace female numbers to male numbers\n",
    "    # dict_male = {\n",
    "    #     \"אחת\": \"אחד\",\n",
    "    #     \"שתיים\": \"שניים\",\n",
    "    #     \"שלושה\": \"שלוש\",\n",
    "    #     \"ארבעה\": \"ארבע\",\n",
    "    #     \"חמישה\": \"חמש\",\n",
    "    #     \"שישה\": \"שש\",\n",
    "    #     \"שבעה\": \"שבע\",\n",
    "    #     \"תשעה\": \"תשע\",\n",
    "    #\n",
    "    # }\n",
    "    # for female, male in dict_male.items():\n",
    "    #     hebrew_text = hebrew_text.replace(female, male)\n",
    "    # postproccessing, removing special charcteres after handling and translating them\n",
    "    valid_tokens = \"פ ם ן ו ט א ר ק ף ך ל ח י ע כ ג ד ש ץ ת צ מ נ ה ב ס ז 1 2 3 4 5 6 7 8 9 0\"\n",
    "    valid_tokens = set([x.lower() for x in valid_tokens])\n",
    "    # The caret in the character class ([^) means match anything but\n",
    "    invalid_chars_regex = f\"[^\\s{re.escape(''.join(set(valid_tokens)))}]\"\n",
    "\n",
    "\n",
    "    \"\"\" DO ADAPT FOR YOUR USE CASE. this function normalizes the target text. \"\"\"\n",
    "    hebrew_text = re.sub(invalid_chars_regex, \" \", hebrew_text)\n",
    "    hebrew_text = re.sub(\"\\s+\", \" \", hebrew_text).strip()\n",
    "    # --- return result\n",
    "    return hebrew_text    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244d2cd",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Preprocessing </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d0715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae5ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBO_SOURCE = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/wavs/\"\n",
    "ROBO_SR_16  = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_16K/\"\n",
    "ROBO_SR_8   = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d3c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [15:33<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "convert = False\n",
    "\n",
    "if convert is True:\n",
    "    list_file_name      = [entry for entry in os.listdir(ROBO_SOURCE) if os.path.isfile(os.path.join(ROBO_SOURCE, entry))]\n",
    "\n",
    "    for file_name in tqdm(list_file_name):\n",
    "\n",
    "        full_file_name = f\"{ROBO_SOURCE}/{file_name}\"\n",
    "        full_sr_16     = f\"{ROBO_SR_16}/{file_name}\"\n",
    "        full_sr_8      = f\"{ROBO_SR_8}/{file_name}\"\n",
    "\n",
    "        current_sr     = get_sample_rate(full_file_name)\n",
    "        if 44100 != current_sr:\n",
    "            print(f\"Source Sample Rate: {current_sr}\")\n",
    "            continue\n",
    "\n",
    "        convert_to_16sr_file(full_file_name, full_sr_16)\n",
    "        convert_to_8sr_file(full_file_name, full_sr_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d334d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/metadata.csv\", sep=\"|\", names=[\"file\", \"gt\", \"gt2\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "372afc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>gt</th>\n",
       "      <th>gt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gold_000_line_000</td>\n",
       "      <td>שָׁלוֹם, צְלִיל אַבְרָהָם.</td>\n",
       "      <td>שָׁלוֹם, צְלִיל אַבְרָהָם.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gold_000_line_001</td>\n",
       "      <td>לְגַמְרֵי, מַדְהִים, לֹא?</td>\n",
       "      <td>לְגַמְרֵי, מַדְהִים, לֹא?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gold_000_line_002</td>\n",
       "      <td>וְדַוְוקָא בִּגְלַל שֶׁכּוּלָּנוּ הָיִינוּ עֲס...</td>\n",
       "      <td>וְדַוְוקָא בִּגְלַל שֶׁכּוּלָּנוּ הָיִינוּ עֲס...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gold_000_line_003</td>\n",
       "      <td>אָז הַיּוֹם אֲנַחְנוּ נְדַבֵּר עַל הַחֲקִירָה ...</td>\n",
       "      <td>אָז הַיּוֹם אֲנַחְנוּ נְדַבֵּר עַל הַחֲקִירָה ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gold_000_line_004</td>\n",
       "      <td>הָרָמַת מָסַךְ מֵעַל סְבַךְ שֶׁל אִינְטֶרֶסִים...</td>\n",
       "      <td>הָרָמַת מָסַךְ מֵעַל סְבַךְ שֶׁל אִינְטֶרֶסִים...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                file                                                 gt  \\\n",
       "0  gold_000_line_000                         שָׁלוֹם, צְלִיל אַבְרָהָם.   \n",
       "1  gold_000_line_001                          לְגַמְרֵי, מַדְהִים, לֹא?   \n",
       "2  gold_000_line_002  וְדַוְוקָא בִּגְלַל שֶׁכּוּלָּנוּ הָיִינוּ עֲס...   \n",
       "3  gold_000_line_003  אָז הַיּוֹם אֲנַחְנוּ נְדַבֵּר עַל הַחֲקִירָה ...   \n",
       "4  gold_000_line_004  הָרָמַת מָסַךְ מֵעַל סְבַךְ שֶׁל אִינְטֶרֶסִים...   \n",
       "\n",
       "                                                 gt2  \n",
       "0                         שָׁלוֹם, צְלִיל אַבְרָהָם.  \n",
       "1                          לְגַמְרֵי, מַדְהִים, לֹא?  \n",
       "2  וְדַוְוקָא בִּגְלַל שֶׁכּוּלָּנוּ הָיִינוּ עֲס...  \n",
       "3  אָז הַיּוֹם אֲנַחְנוּ נְדַבֵּר עַל הַחֲקִירָה ...  \n",
       "4  הָרָמַת מָסַךְ מֵעַל סְבַךְ שֶׁל אִינְטֶרֶסִים...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2b5733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoboshaulGoldDataset(Dataset):\n",
    "        \n",
    "    def __init__(self, source_folder, df_gt, device):        \n",
    "        \n",
    "        self.list_file_names = [entry for entry in os.listdir(ROBO_SOURCE) if os.path.isfile(os.path.join(ROBO_SOURCE, entry))]        \n",
    "        self.l_file_name     = []\n",
    "        self.l_full_path     = []\n",
    "        self.l_gt            = []\n",
    "        self.device          = device\n",
    "        \n",
    "        for file_name in tqdm(list_file_name):\n",
    "\n",
    "            # --- get GT text            \n",
    "            gt         = df_gt[df_gt['file'] == file_name[:-4]]['gt'].values[0]            \n",
    "            full_src   = f\"{source_folder}/{file_name}\"       \n",
    "            \n",
    "            self.l_file_name.append(file_name)\n",
    "            self.l_full_path.append(full_src)                \n",
    "            self.l_gt.append(gt)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l_gt)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        audio_file_path = self.l_full_path[idx]        \n",
    "        audio           = whisper.load_audio(str(audio_file_path))\n",
    "        audio           = whisper.pad_or_trim(audio)\n",
    "        \n",
    "        mel             = whisper.log_mel_spectrogram(audio).to(self.device)        \n",
    "        \n",
    "        sample          = {'mel':      mel, \n",
    "                          'text':      HebrewNormalizer(self.l_gt[idx]), \n",
    "                          'file':      self.l_file_name[idx],                          \n",
    "                          'full_path': self.l_full_path[idx]}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5996b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_whisper_on_rambo(loader, res_file_name, lang):\n",
    "    df = pd.DataFrame()\n",
    "    for batch in tqdm(loader):\n",
    "        \n",
    "        languages        = []\n",
    "        if lang is not None:\n",
    "            languages = [lang]        \n",
    "        mel              = batch['mel']\n",
    "        audio_data       = {'wav': json.dumps(mel.tolist()), 'languages': languages}\n",
    "        gt               = batch['text']\n",
    "\n",
    "        #res              = requests.get('http://10.53.140.33:80/batch_inference/', json=audio_data)\n",
    "        res              = requests.get('http://10.53.140.33:80/batch_inference_beam/', json=audio_data)\n",
    "        res_list         = res.json()[0]\n",
    "\n",
    "        l_wer            = []\n",
    "        l_whisper        = []    \n",
    "        l_res_lang       = []\n",
    "        l_avg_logprob    = []\n",
    "        l_no_speech_prob = []\n",
    "        l_compres_ratio  = []\n",
    "\n",
    "        for i, res in enumerate(res_list):\n",
    "            whisper_text = res['text']\n",
    "            whisper_text = HebrewNormalizer(whisper_text)\n",
    "            l_whisper.append(whisper_text)                \n",
    "            if whisper_text == '':\n",
    "                l_wer.append(1)\n",
    "            else:\n",
    "                l_wer.append(jiwer.wer(whisper_text, gt[i]))\n",
    "            l_res_lang.append(res['language'])\n",
    "            l_avg_logprob.append(res['avg_logprob'])\n",
    "            l_no_speech_prob.append(res['no_speech_prob'])\n",
    "            l_compres_ratio.append(res['compression_ratio'])\n",
    "\n",
    "\n",
    "        df_tmp     = pd.DataFrame({\n",
    "            \"whisper\":           l_whisper,\n",
    "            \"gt\":                gt,\n",
    "            \"wer\":               l_wer,\n",
    "            \"file\":              batch['file'],            \n",
    "            \"full_path\":         batch['full_path'],\n",
    "            \"detect_lang\":       l_res_lang,\n",
    "            \"avg_logprob\":       l_avg_logprob,\n",
    "            \"no_speech_prob\":    l_no_speech_prob,\n",
    "            \"compression_ratio\": l_compres_ratio,\n",
    "\n",
    "        })\n",
    "        df = pd.concat([df, df_tmp], ignore_index=True)        \n",
    "        df.to_csv(res_file_name)\n",
    "        \n",
    "            \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65251b2e",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Test With SR=16K </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c502ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [00:01<00:00, 2984.51it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_16k = RoboshaulGoldDataset(source_folder = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_16K\",\n",
    "                               df_gt         = df_meta,\n",
    "                               device        = DEVICE)\n",
    "\n",
    "loader_16k = DataLoader(dataset_16k, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_whisper_on_sr_16 = False\n",
    "if run_whisper_on_sr_16 is True:\n",
    "    run_whisper_on_rambo(loader_16k, \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_16k.csv\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96931189",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Test With SR=8K </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbb26b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2986/2986 [00:00<00:00, 3053.25it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_8k = RoboshaulGoldDataset(source_folder = \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/WAV_SR_8K\",\n",
    "                               df_gt         = df_meta,\n",
    "                               device        = DEVICE)\n",
    "\n",
    "loader_8k = DataLoader(dataset_8k, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73084b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_whisper_on_sr_8 = False\n",
    "if run_whisper_on_sr_8 is True:\n",
    "    run_whisper_on_rambo(loader_8k, \"/home/amitli/Datasets/Roboshaul/saspeech_gold_standard_v1.0/saspeech_gold_standard/robo_whisper_8k.csv\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa684c2",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> Compare Results </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1aeda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
